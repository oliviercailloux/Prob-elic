\RequirePackage[l2tabu, orthodox]{nag}
\documentclass[version=3.21, pagesize, twoside=off, bibliography=totoc, DIV=calc, fontsize=12pt, a4paper]{scrartcl}
\input{preamble/packages}
\input{preamble/redac}
\input{preamble/math_basics}
\input{preamble/math_mine}
%I find these settings useful in draft mode. Should be removed for final versions.
	%Which line breaks are chosen: accept worse lines, therefore reducing risk of overfull lines. Default = 200.
		\tolerance=2000
	%Accept overfull hbox up to...
		\hfuzz=2cm
	%Reduces verbosity about the bad line breaks.
		\hbadness 5000
	%Reduces verbosity about the underful vboxes.
		\vbadness=1300

\title{Probabilistic elicitation of preferences \thanks{Draft!}}
\author{Nicolas Boria}
\author{Olivier Cailloux}
\author{Marc Pirlot}
\affil{Université Paris-Dauphine, PSL Research University, CNRS, LAMSADE, 75016 PARIS, FRANCE\\
	\href{mailto:olivier.cailloux@dauphine.fr}{olivier.cailloux@dauphine.fr}
}

\begin{document}
\maketitle

\section{Introduction}
Many studies have investigated the computational complexity of (variants of) sorting problems. The usual implicit hypothesis is that the number of objects to be sorted is large, and that we are mostly interested in order of magnitudes of number of comparisons required to achieve some desired state of knowledge, rather than exact number of comparisons.

This article focuses on a different use case: obtaining preference information from an individual over a small set of objects. We assume furthermore that determining her preference among objects of the set is cognitively difficult for the individual. For example, one may be interested in determining (part of) someone’s preferences over a set of political candidates; or some juror “preferences” over competitors in some contest.

This problem can be viewed as a variant of a sorting task, where the ordering relation is the one determined by the individual’s preference. Querying for her preference is akin to a comparison in a sorting task. In such a setting, however, contrary to the implicit hypothesis in sorting tasks, it is important to focus on precise bounds on the number of comparisons, not just asymptotic orders of magnitude. This is for two reasons. First, the set of objects should generally be supposed to be small. That is because individuals will not accept to answer hundreds of comparison questions. Furthermore, when such comparison questions is cognitively difficult, a gain of a constant factor in terms of number of comparisons is important.

An example of an application of the sorts of results we seek is in social choice. In social choice, one typically assumes that the voters preferences are known, and studies focus on merits of aggregation rules. However, in many cases, the preferences must be elicited. A typical case is the one of a recrutment committee. Our results aim at indicating how to obtain (partial) information about the preferences of the members of the committee over the set of candidates. This can then be used, for example, to compute necessary or possible winners.

\section{Set up and goal}
\begin{itemize}
	\item $\allalts$ a set of objects. Example: $\allalts = {a, b, c}$.
	\item $n = |\allalts|$. Example: $n = 3$.
	\item $\linors$ the set of linear orders over $\allalts$, that is, of transitive and complete binary relations over $\allalts$ (a relation $\prefeq$ over $\allalts$ is complete iff $\forall i, j \in \allalts: i \pref j \lor j \pref i$).
	\item ${\prefeq} \in \linors$ a preference over $\allalts$. Example: $\set{(a, b), (a, c), (b, c)}$. Let $\pref$ be the irreflexive part of $\prefeq$, thus, ${\prefeq} = ({\pref} \cup {=})$.
	\item Let $\powerset{S}$ denote the set of subsets of $S$.
Let $P: \powerset{\linors} → [0, 1]$ denote a probability distribution over the possible preferences.
\end{itemize}
The preference $\prefeq$ is a priori unknown.
We only know the probability distribution over $\linors$, from which $\prefeq$ is drawn. 
We can ask questions to obtain information about $\prefeq$. 
We are interested in comparing questioning strategies and in evaluating the probabilistic evolution of our knowledge of $\prefeq$ as a function of the number of questions asked, for various strategies. 

\section{Questioning to increase our knowledge}
Let $\POs$ denote the set of partial orders over $\allalts$. A partial order ${\pprefeq} \subseteq \allalts × \allalts$ is a transitive, reflexive and antisymmetric relation.
It represents our knowledge of $\prefeq$.
Let $\ppref$ be the irreflexive part of $\pprefeq$, thus, ${\pprefeq} = ({\ppref} \cup {=})$.

Let $\pprefeq_t$ denote our knowledge after $t$ questions (or $\ppref_t$ for its irreflexive part).
Define ${\ppref_0} = \emptyset$ as our (empty) knowledge after zero questions.
Example of $\ppref_1 : \set{(a, b)}$.

A question $q \in Q$ is a non-oriented edge, which formally we consider as two edges, inverse of each other. Let $q_{ij} = \set{(i, j), (j, i)}$ denote the question about ${i, j}$, with $i ≠ j \in \allalts$.
Note that $q_{ij} = q_{ji}$.
The set of possible questions is $Q = \set{q_{ij} \suchthat i ≠ j \in \allalts}$.
It follows that $\card{Q} = \binom{n}{2} = \frac{n (n - 1)}{2}$. In our running example, $\card{Q} = 3$.

Given $i ≠ j \in \allalts$, ${\pref} \cap q_{ij}$ is a singleton that contains the answer to the question $q_{ij}$ when the preference is $\pref$, that is, the edge connecting $i$ to $j$ that is in $\pref$.
Define an addition operation representing our increase in knowledge after having obtained an answer to a question: we add the resulting pair, and compute the transitive closure. Formally, given $\ppref$ and a question $q$, ${\ppref} + ({\pref} \cap q) = T({\ppref} \cup ({\pref} \cap q))$, where $T$ denotes the irreflexive transitive closure ($T(p) = \bigcup_{k \in N^*} p^k$). Example: $\set{(a, b)} + ({\pref} \cap q_{bc}) = {\pref}$.

Let ${\ppref^{±1}} = {\ppref} \cup {\ppref^{-1}}$ denote the set of pairs known in $\ppref$, thus, $q \subseteq {\ppref^{±1}}$ iff the answer to the question $q$ is known in $\ppref$.

%Let $K_\ppref = \set{\set{e, e^{-1}} \suchthat e \in {\ppref}} \subseteq Q$ denote the questions whose answer is known in $\ppref$. Note that $\card{K_\ppref} = \card{{\ppref}}$.
%Let $Q_\ppref = Q \setminus K_\ppref$ denote the questions remaining given $\ppref$. Note that $\card{Q_\ppref} = \card{Q} - \card{K_\ppref}$.
%Note that if we obtain at least one edge per step, then after $\card{Q}$ steps, our knowledge is complete: $Q_{\ppref_{\card{Q}}} = \emptyset$.

\subsection{Sequences of questions, of partial orders, and of digraphs}
\label{seq:uniqueQs}
Sequences of questions can be related to sequences of partial orders and to sequences of digraphs.
This section shows that if a sequence of partial orders corresponds to a sequence of questions, it corresponds to a unique sequence of questions.

Define the upper contour set of $x \in X$ as ${\pprefeqinv}(x) = \set{y \in X \suchthat y \pprefeq x}$, thus, as the set of objects that are at least as good as $x$.
We first observe that a subset of an upper contour set that includes an object of which it is the upper contour set is the upper contour set of a unique object.
(A similar results holds for lower contour sets.)
\begin{proposition}[Folklore?]
	\label{th:ucs}
	Let $\set{x, y} \subseteq S \subseteq X$ such that $S \subseteq {\pprefeqinv}(x)$ and $S \subseteq {\pprefeqinv}(y)$. Then, $x = y$.
\end{proposition}
\begin{proof}
	By hypothesis, $x \in S$, and $\forall s \in S: s \pprefeq y$. Thus, $x \pprefeq y$.
	By a symmetrical observation, $y \pprefeq x$.
	Because $\ppref$ is asymmetric and ${\pprefeq} = {\ppref} \cup \restr{=}{X}$, this implies $x = y$.
\end{proof}

Given ${\ppref}, {\ppref'} \in \POs$ and $i, j \in \allalts$, say that the question $q_{ij} \in Q$ may lead from $\ppref$ to $\ppref'$ iff ${\ppref'} = {\ppref} + (i, j) \lor{\ppref'} = {\ppref} + (j, i)$.

Given ${\ppref}, {\ppref'} \in \POs$, say that the transition from $\ppref$ to $\ppref'$ is legal iff some question may lead from $\ppref$ to $\ppref'$.
Given $k \in \N$, let $\intvl{1, k}$ denote the interval of integers between $1$ and $k$.
Say that a sequence of partial orders $(\ppref_t) \in \POs^k$ is legal iff the transition from $\ppref_t$ to $\ppref_{t + 1}$ is legal $\forall t \in \intvl{1, k - 1}$.

Any legal sequence of partial orders defines uniquely a corresponding sequence of questions. The following proposition shows that any two adjacent partial orders in a legal sequence together define uniquely the left member of the answer that was added. As a similar result holds, by symmetry, for the right member, this proves the point.
\begin{proposition}
	Given ${\ppref}, {\ppref'} \in \POs$ and $i, j \in X$ such that ${\ppref'} = {\ppref} + (i, j)$, $i$ is determined uniquely by ${\ppref}$ and ${\ppref'}$.
\end{proposition}
\begin{proof}
	Let $N = {\ppref'} \setminus {\ppref}$ be the set of pairs brought thanks to the answer $(i, j)$. Suffices to prove that $N$ determine $i$ uniquely. 
	
	Consider $M = (N \cup {=})$, the reflexive relation equivalent to $N$.
	By definition of $+$, $M \subseteq \set{(i', j') \suchthat i' ≥ i \land j ≥ j'}$. 
	Let $L = M^{-1}(\allalts)$ be the left projection of $M$. 
	We see that $L$ includes $i$ and is a subset of the upper contour set of $i$. 
	\Cref{th:ucs} thus concludes.
\end{proof}

We can also think of $\ppref$ as a directed graph, or digraph, whose set of nodes is $\allalts$. We thus define a bijection that relates $\ppref$ to $G = (\allalts, \ppref)$, its corresponding digraph, and talk interchangeably about a digraph or a set of edges or a partial order. This bijection defines the possible digraphs: those having nodes $\allalts$ and a transitive and acyclic set of edges.

\section{Questioning strategies and probability distributions}
Given a partial order $\ppref$, we write $P(\ppref) = P(\set{{\pref} \in \linors \suchthat {\ppref} \subseteq {\pref}})$ for the probability that the real preference be compatible with $\ppref$.

Define a questioning strategy as a function $s: \POs \setminus \linors → [0, 1]^Q$ that given a current knowledge state ${\ppref} \in \POs \setminus \linors$ returns a probability distribution over the set of possible questions $Q$. 

The probability distribution $P$ over the possible preferences and a strategy $s$ determine in a natural way several probability distributions. 

Given ${\pref} \in \linors$ and a sequence of questions $(q_t)_{t \in \intvl{1, k}} \in Q^k$ of length $k \in \N^*$, define the corresponding sequence of partial orders $({\ppref}_t)_{t \in \intvl{1, k}} \in \POs^k$ as ${\ppref_0} = \emptyset$ and ${\ppref_t} = {\ppref_{t - 1}} + ({\pref} \cap q_t) = T(\cup_{q \in \set{q_1, …, q_t}} ({\pref} \cap q))$.
Note that if the relation was not complete at step $k - 1$, it also was incomplete before: ${\ppref_{k - 1}} \notin \linors ⇒ \forall t \in \intvl{1, k - 1}: {\ppref_t} \notin \linors$. 

Given ${\prefeq} \in \linors$, define $Q^{\prefeq} = \cup_{k \in \N^*} \set{(q_t)_{t \in \intvl{1, k}} \in Q^k \suchthat {\ppref_{k - 1}} \notin \linors \land {\ppref_k} \in \linors}$ as the set of finite sequences of questions that lead to a linear order just after the last question and not before. 

Given ${\prefeq} \in \linors$ and $(q_t)_{t \in \intvl{1, k}} \in Q^{\prefeq}$ of length $k \in \N^*$, define $P^{\prime s}(\prefeq, (q_t)_{t \in \intvl{1, k}})$ as the probability of ${\prefeq} \in \linors$ being the real preference and of the strategy $s$ asking the sequence of questions $(q_t)_{t \in \intvl{1, k}}$ as: 
\begin{equation}
	P^{\prime s}(\prefeq, (q_t)_{t \in \intvl{1, k}}) = 
	P(\prefeq)  \prod_{t \in \intvl{1, k}} s(\ppref_{t - 1})(q_t).
\end{equation}

For example, $P^{\prime s}(\prefeq, q_1, q_2, q_3)$ denotes the probability that the preference is $\prefeq$ and that the questions, chosen according to the strategy $s$, were $q_1$, then $q_2$, and finally $q_3$.

Given ${\prefeq} \in \linors$, $k \in \N^*$ and $(q_t)_{t \in \intvl{1, k}} \in Q^k$, let $P^{\prime s}(\prefeq, (q_t)_{t \in \intvl{1, k}})$ denote $P^{\prime s}(\prefeq, \set{(q'_t)_{t \in \intvl{1, k'}} \in Q^{\prefeq} \suchthat k' ≥ k \land \restr{q'_t}{\intvl{1, k}} = q_t})$, the probability that the real preference be $\prefeq$ and that the strategy $s$ asks any sequence of questions in $Q^{\prefeq}$ that completes $(q_t)_{t \in \intvl{1, k}}$.

Given $k \in \N^*$, ${\prefeq} \in \linors$ and $(q_t)_{t \in \intvl{1, k}} \in Q^k$ such that ${\ppref}_{k - 1} \notin \linors$, define $P^s(\prefeq, (q_t)_{t \in \intvl{1, k}})$ as the probability of ${\prefeq} \in \linors$ being the real preference and of the strategy $s$ asking the sequence of questions $(q_t)_{t \in \intvl{1, k}}$ as: 
\begin{equation}
	P^s(\prefeq, (q_t)_{t \in \intvl{1, k}}) = 
	P(\prefeq)  \prod_{t \in \intvl{1, k}} s(\ppref_{t - 1})(q_t).
\end{equation}

\begin{proposition}
	$P^s = P^{\prime s}$.
\end{proposition}
\begin{proof}
	This follows from the corresponding definitions.
\end{proof}

\begin{remark}
	We can view $s$ as the conditional probabilities given by $P^s$, as these examples show for the cases of one and two questions (which can be generalized naturally).
	\begin{itemize}
		\item $P^s(q_1 | {\pref}) = P^s({\pref}, q_1) / P^s({\pref}) = P^s({\pref}) s(\emptyset)(q_1) / P({\pref}) = s(\emptyset)(q_1)$.
		\item $P^s(q_2 | {\pref}, q_1) = P^s({\pref}, q_1, q_2) / P^s({\pref}, q_1) = P^s({\pref}, q_1, q_2) / [s(\emptyset)(q_1)P({\pref})] = s(\emptyset)(q_1) s({\ppref}_1)(q_2) / s(\emptyset)(q_1) = s({\ppref}_1)(q_2).$
	\end{itemize}
\end{remark}

As the sequence of questions determines the sequence of partial orders, we can also consider $P^s$ as a probability distribution over (parts of) sequences of partial orders. 
Define accordingly the probability of the real preference being ${\pref}$ and obtaining the knowledge ${\ppref}_t$ after $t$ questions for each $t \in \intvl{1, k}$, given ${\pref} \in \linors$ and a finite sequence of preorders $({\ppref}_t)_{t \in \intvl{1, k}} \in \POs^k$ of length $k$, as: 
\begin{equation}
	P^s({\pref}, ({\ppref}_t)_{t \in \intvl{1, k}}) = 
P^s({\pref}, \set{(q_t)_{t \in \intvl{1, k}} \suchthat \forall t \in \intvl{1, k}: T(\cup_{i ≤ t} (q_i \cap {\pref})) = {\ppref}_t}).
\end{equation}
As \cref{seq:uniqueQs} show that the set of sequences of questions corresponding to the sequence of preorders is a singleton if not empty, we obtain:
\begin{equation}
	P^s({\pref}, ({\ppref}_t)_{t \in \intvl{1, k}}) = 
	\begin{cases}
		P({\pref}) \prod_{t \in \intvl{1, k}} s(\ppref_{t - 1})(q_t) & \text{ if } (q_t)_{t \in \intvl{1, k}} \text{ corresponds to } ({\ppref}_t)_{t \in \intvl{1, k}},\\
		0 & \text{ if none correspond}.
	\end{cases}
\end{equation}

We also note $P^s({\ppref}_i) = P^s(\set{({\ppref'_t})_{t \in \intvl{1, k}} \in \cup_{i ≤ k \in \N^*} \POs^k \suchthat {\ppref'_i} = {\ppref}_i})$, given $i \in \N^*$, for the probability of our knowledge being ${\ppref}_i$ after $i$ questions.
\begin{remark}
	Note that this is a double abuse of notation. First, it introduces a possible ambiguity: $P^s({\ppref}_1) = \sum_{{\pref} \in \linors} P({\pref}) s(\emptyset)(\set{q \suchthat (q \cap {\pref}) = {\ppref_1}})$ represents the probability of obtaining a knowledge of $\ppref_1$ after one question, whereas $P^s({\ppref}) = P({\ppref})$ represents the probability that the real ordering $\pref$ be a superset of ${\ppref}$. Also, the index is important, as $P^s({\ppref}_1)$ may differ from $P^s({\ppref}_2)$. We shall use indices systematically to denote the first interpretation, with the index referring to the number of questions.
\end{remark}
\begin{example}
Example: $P^s({\ppref_1} = \set{(a, b)}) = P^s(q_1 = q_{ab} \land a \pref b)$.
Example: $P^s({\ppref_2} = \set{(a, b), (c, b)}) = P^s\big(\set{q_1, q_2} = \set{q_{ab}, q_{bc}} \land a \pref b \land c \pref b\big)$.
Example: $P^s({\ppref_2} = \set{(a, b), (b, c)}) = P^s\big(\set{q_1, q_2} = \set{q_{ab}, q_{bc}} \land a \pref b \land b \pref c\big)$.
Example: $P^s({\ppref_3} = \set{(a, b), (b, c)}) = P^s\big(\set{q_1, q_2, q_3} \supseteq \set{q_{ab}, q_{bc}} \land a \pref b \land b \pref c\big)$.
\end{example}

Define $P^\mathit{eq}$ as the equiprobable distribution over $\linors$, thus, $\forall {\pref} \in \linors: P^\mathit{eq}(\pref) = 1/\card{\linors}$.

Given $i, j \in \allalts$, $k \in \N$, let $P^s(i \ppref_k j) = P^s((i, j) \in {\ppref_k})$ denote the probability that the edge $(i, j)$ be known after $k$ questions. (Under reasonable conditions of symmetry on $P$ and $s$, this will be half of $P^s(q_{ij} \subseteq {\ppref^{±1}_k})$, the probability that the answer to the question $q_{ij}$ be known after $k$ questions.)

Can we obtain a nice formula for $P^s(i \ppref_k j)$?

\subsection{Optimal strategies}
\label{sec:optDef}
The optimal $k$-strategies $\argmax_{s} E^s[\card{{\ppref}_k}]$ are defined as those that maximize the expected number of known pairs after $k$ questions:
\begin{equation}
	E^s[\card{{\ppref}_k}] = \sum_{{\ppref}_k \in \POs} \prod P^s({\ppref}_k) \card{{\ppref_k}}.
\end{equation}

We have:
\begin{align}
	E^s[\card{{\ppref}_k}] 
	& = \sum_{({\ppref}_t)_{t \in \intvl{1, k}} \in \POs^k} P^s(({\ppref}_t)_{t \in \intvl{1, k}}) \card{{\ppref_k}}\\
	& = \sum_{{\pref} \supseteq {\ppref}_k \supseteq {\ppref}_{k - 1} \supseteq … \supseteq {\ppref}_1} P^s({\pref}, ({\ppref_t})_{t \in \intvl{1, k}}) \card{{\ppref_k}}\\
	& = \sum_{{\pref} \supseteq {\ppref}_k \supseteq {\ppref}_{k - 1} \supseteq … \supseteq {\ppref}_1} P({\pref}) \prod_{t \in \intvl{1, k}} s({\ppref_{t - 1}})(q_t) \card{{\ppref_k}}.
\end{align}
(The last two sums are over sequences that are feasible, meaning that for any $t \in \intvl{1, k}$, some question permits to go from ${\ppref}_{t - 1}$ to ${\ppref_t}$.)

The optimal $k$-strategies knowing $\ppref$ are defined as the strategies maximizing:
\begin{align}
	E^s[\card{{\ppref}_k} \knowing {\ppref}]
	& = \sum_{{\ppref}_k \in \POs} P^s({\ppref}_k \knowing {\ppref}) \card{{\ppref_k}}.
\end{align}

The gain due to transitivity when asking $q$ when knowing ${\ppref}$ and when the real preference is ${\pref}$ is defined as $g^{q, {\ppref}}({\pref}) = \card{T({\ppref} \cup (q \cap {\pref}))} - \card{{\ppref}} - 1$.

Because $g^{q, {\ppref}}$ is a random variable, we can also define the expected gain knowing ${\ppref}$ as $E[g^{q, {\ppref}} \knowing {\ppref}] = \prod_{{\pref} \supseteq {\ppref}} P({\pref} \knowing {\ppref}) × g^{q, {\ppref}}({\pref})$.

We also define the myopically best question when knowing ${\ppref}$ as $\hat{q}({\ppref}) = \argmax_{q \in Q} E[g^{q, {\ppref}} \knowing {\ppref}]$, and define, abusing notation, $g({\ppref}) = \max_{q \in Q} E[g^{q, {\ppref}} \knowing {\ppref}]$.

%g^> = g^{myopic-best-q(>), >} NOT WELL DEFINED: There could be q1 and q2 with same exp but ≠ resulting gain functions: g^q1(t_1) = 3; g^g1(t_2) = 1; g^q2(t_1) = 1; g^q2(t_2) = 3.


\subsection{Random questions without repetition}
The random strategy without repetition $s^\mathit{rm}$ draws a question equiprobably from the set of remaining questions. Thus, $\forall {\ppref} \in \POs \setminus \linors, i ≠ j \in \allalts$:
\begin{equation}
	s^\mathit{rm}(\ppref)(q_{ij}) = 
	\begin{cases}
		\frac{1}{\card{(X^2 \setminus {\pprefeq}^{±1})} / 2} & \text{ if } q_{ij} \nsubseteq {\ppref^{±1}},\\
		0 & \text{ if } q_{ij} \subseteq {\ppref^{±1}},
	\end{cases}
\end{equation}
where $\card{(X^2 \setminus {\pprefeq}^{±1})} / 2$ represents the number of questions remaining when knowing $\ppref$.

\subsection{Questioning by sorting a subset of objects}
Given a budget of $k$ questions, we can adopt the following questioning strategy. Fix $l$ objects such that they can be sorted by asking at most $k$ questions (thus $l$ greater than order of $\frac{k}{\log k}$?). Ask questions so as to sort them. We obtain $\card{{\ppref}} = \binom{l}{2}$.
Thus, perhaps, $\card{{\ppref}}$ is order of $\binom{k / \log k}{2}$.
TODO: be more precise.

\subsection{Median strategy}
(Thanks to Michail.)
Given a budget of $k$ questions, we can adopt the following questioning strategy. 
Fix $l$ objects.
Ask questions so as to: 1) determine their median in $\pref$ (“this can be done with O(l) comparisons deterministically”) and 2) partition the subset of $l$ objects among $\frac{l}{2}$ objects preferred to the median and $\frac{l}{2}$ other ones.
We obtain $\card{{\ppref}} = \frac{l^2}{4}$.
Thus, $\card{{\ppref}}$ order of $\frac{k^ 2}{4}$.
TODO: be more precise. See \hrefblue{https://en.wikipedia.org/wiki/Median_of_medians\#Proof_of_O(n)_running_time}{Median of medians}; Knuth, Sorting and Searching, vol. 3; Cormen, Intro to algorithms…

Here is an algorithm to select a median of $n$ elements, with worst case complexity $O(n^2)$ and average complexity $O(n)$ (the lower or the upper median are both acceptable results).
Select a pivot element randomly (equiprobably). Compare the $n - 1$ other elements to the pivot. Run again on either the lower elements or the higher elements, depending on where the median lies, or stop if a median has been found. 

Let $V_[m_1, m_2](n)$ be the number of comparisons required to find the $m_1$th or $m_2$th element among $n$, $V_m(n)$ for $V_{[m, m]}(n)$, $V(n)$ for $V_[\floor{\frac{n}{2}}](n)$, and let us compute an upper bound for $E[V(n)]$.
Because of our equiprobable pivot draw, we have $1/n$ chances to pick a pivot that will turn out the be the $k$ th element (in order). Assume, pessimistically, that we always recurse on the biggest partition. If we picked a pivot that is the first or last element (that happens with odds $2/n$), we recurse on a partition of size $n - 1$. And so on (if $n$ is odd, one of the terms appears only once instead of twice). We obtain $E[V(n)] ≤ \frac{2}{n} \sum_{k = \floor{n/2}}^{n - 1} E[V(k)] + (n - 1)$.

A classical result is that $E[V(n)] \in O(n)$ [Cormen et al.].

That bound is tight for $1 ≤ n ≤ 2$, as $V(1) = 0$ and $V(2) = 1$. Also, $E[V(3)] = 2 + \frac{2}{3}$ and $E[V(4)] = 3 + \frac{1}{2}E[V(3, [1, 2])] = 4 + \frac{1}{3}$.

\section{The equiprobable distribution}
Here we consider $P = P^\mathit{eq}$. 

\subsection{Some probabilities}
We shall use the following notation:
\begin{itemize}
    \item $|A|$ denotes the cardinal of the finite set $A$;
    \item if $>$ is a relation on $X$ and $X' \subseteq{X}$, $>_{|X'}$ is the restriction of $>$ to $X'$, i.e., the set of pairs $a,b \in X'$ such that $a>b$.
\end{itemize}

\begin{lemma}\label{le:equalProba}
	\label{th:equalProba}
Let $X' \subseteq X$ and ${\ppref}, {\ppref'} \in \linors[X']$. We have $P(\ppref) = P(\ppref')$.
\end{lemma}
\begin{proof}
By definition, $P(\ppref) = P(Y)$, where $Y = \set{{\pref[e]} \in \linors[X]: \restr{{\pref[e]}}{X'} = {\ppref}})$.  Similarly,  $P(\ppref')= P(Y')$, where $Y' = \set{{\pref[\prime e]} \in \linors: \restr{{\pref[\prime e]}}{X'} = {\ppref'}})$.

The distribution being uniform on all linear orders on $X$, the sets $Y$ and $Y'$ have equal probability because they have the same cardinality. This is intuitively clear. To be sure, we establish a bijection between these two sets. Considering any element ${\pref[e]} \in Y$, we will associate to it an element ${\pref[\prime e]} \in Y'$, thanks to the following concept of a rank function.

Every linear order ${\pref[c]} \in \linors$ uniquely corresponds to a bijection $\sigma: X \rightarrow \set{1, …, n}$ such that $a \pref[c] b $ iff $\sigma(a) > \sigma(b)$ (where $>$ denotes the order on the natural numbers). 
\commentOC{Can we write: … such that $\sigma(a) = \card{{\pref[c]}(a)} = \card{\set{b \in X \suchthat a \pref[c] b}}$?}
We can interpret $\sigma$ as the \emph{rank} function (the larger the rank, the better). 

Let $\sigma$ denote the rank function associated to $\pref[e]$. 
The set $\sigma(X')$ is the set of ranks of the elements in $X'$ w.r.t. the order $\ppref$ on $X'$ (since ${\pref[e]} \in Y$). Let $\tau: X' \rightarrow X'$ be the permutation that maps the  element of rank $i$ w.r.t.\ $\ppref$ onto the element of same rank $i$ w.r.t.\  $\ppref'$. We have, for all $a,b \in X'$, $a \ppref b$ iff $\tau(a) \ppref' \tau(b')$. Each element ${\pref[e]} \in Y$ is uniquely associated to the element ${\pref[\prime e]} \in Y'$, which is defined as follows by its rank function $\sigma'$: $\sigma'(a) = \sigma (a)$, for all $a\in X\setminus{X'}$ and $\sigma'(a) = \sigma(\tau^{-1}(a)$, for all $a \in X'$. It is easily checked that this correspondence is bijective.   
\end{proof}
\begin{proof}[Alternative, with lower contour sets]
	Same first two paragraphs.
	
	Define a bijection $\tau: X' → X'$ that associates to an element $a \in X'$ of rank $i$ in $\ppref$ the element that has rank $i$ in ${\ppref'}$. Extend it to a bijection $t: X → X$ defined as $t = \tau \cup \restr{{=}}{X \setminus X'}$, thus, that associates the elements of $X$ not in $X'$ to themselves.
	
	Define the transformation from ${\pref[e]} \in Y$ to ${\pref[\prime e]} \in Y'$ as ${\pref[\prime e]} = t \circ {\pref[e]} \circ t^{-1}$, by which we mean that ${\pref[\prime e]}(a)$, the lower contour set of $a$ in $\pref[\prime e]$, equals the lower contour set of $t^{-1}(a)$ in $\pref[e]$ transformed by $t$. As $t$ is a bijection, this transformation is a bijection. See \cref{fig:equalProba}.
\end{proof}
\begin{figure}
	\begin{tikzpicture}
		\path node (>) {$\ppref$};
		\path (>) ++(0, -5mm) node (a) {$a$};
		\path (a) ++(0, -5mm) node (c) {$c$};
		\path (c) ++(0, -5mm) node (b) {$b$};
		\path (>) ++(2cm, 0) node (>') {$\ppref'$};
		\path (>') ++(0, -5mm) node (c') {$c$};
		\path (c') ++(0, -5mm) node (b') {$b$};
		\path (b') ++(0, -5mm) node (a') {$a$};
		\path [draw, ->] (c) edge node {$\tau$} (b');

		\path (b) ++(0, -2cm) node (>e) {$\pref[e]$};
		\path (>e) ++(0, -5mm) node (xe) {$x$};
		\path (xe) ++(0, -5mm) node (ae) {$a$};
		\path (ae) ++(0, -5mm) node (ce) {$c$};
		\path (ce) ++(0, -5mm) node (be) {$b$};
		\path (be) ++(0, -5mm) node (ye) {$y$};
		\path (ye) ++(0, -5mm) node (ze) {$z$};
		\path (>e) ++(2cm, 0) node (>e') {$\pref[\prime e]$};
		\path (>e') ++(0, -5mm) node (xe') {$x$};
		\path (xe') ++(0, -5mm) node (ce') {$c$};
		\path (ce') ++(0, -5mm) node (be') {$b$};
		\path (be') ++(0, -5mm) node (ae') {$a$};
		\path (ae') ++(0, -5mm) node (ye') {$y$};
		\path (ye') ++(0, -5mm) node (ze') {$z$};
		\path [draw, ->] (ce) edge node {$t$} (be');
	\end{tikzpicture}
	\caption{Illustration for \cref{th:equalProba} with $X' = \set{a, b, c}$ and $X = X' \cup \set{x, y, z}$}
	\label{fig:equalProba}
\end{figure}

\begin{proposition}\label{th:probaLinearOrder}
	Consider any $X' \subseteq X$ and any ${\ppref} \in \linors[X']$. $P(\ppref) = 1 / (\card{X'})!$.
\end{proposition}
\begin{proof} By \cref{th:equalProba}, $P(\ppref) = P(\ppref')$, for all ${\ppref}, {\ppref'} \in \linors[X']$. Since the cardinal of $\linors[X']$ is $|X'|!$, for all ${\ppref} \in \linors[X']$, $P(\ppref) =  \frac{1}{|X'|!}$.
\end{proof}

\begin{lemma}\label{th:probaPartialOrder}
Let $X' \subseteq X$. Given ${\ppref} \in \POs[X']$, a partial order on $X'$: 
\begin{equation}
	P(\ppref) = \frac{|\set{{\ppref'} \in \linors[X']: {\ppref'} \supseteq {\ppref}}|}{|X'|!}.
\end{equation}
\end{lemma}
\begin{proof}
$P(\ppref) = P(\set{{\pref[e]} \in \linors: {\pref[e]} \supseteq {\ppref}})$. We have that 
\begin{equation}
	\set{{\pref[e]} \in \linors: {\pref[e]} \supseteq {\ppref}} = \bigcup_{{\ppref'} \in \linors[X']: {\ppref'} \supseteq {\ppref}} \set{{\pref[e]} \in \linors: \restr{{\pref[e]}}{X'} = {\ppref'}}.
\end{equation}
The latter union is disjoint. Therefore, 
\begin{equation}
	P(\set{{\pref[e]} \in \linors: {\pref[e]} \supseteq {\ppref}}) = \sum_{{\ppref'} \in \linors[X']: {\ppref'} \supseteq {\ppref}} P({\ppref'}).
\end{equation}
Using \cref{th:probaLinearOrder}, we get the result.
\end{proof}

The following proposition is a corollary of the previous lemma. 
\begin{proposition}
	Consider any $X' \subseteq X$ and any partial order $\ppref$ over $X'$. Its probability $P(\ppref)$ is independent of $n$.
\end{proposition}

\begin{proposition}[draft!]
	\label{th:indep}
	Given $X' \subseteq X$, ${\ppref} \in \POs[X']$ with a single connected component containing only incomparable elements better than $b$ and incomparable elements below $b$, and $a, b \in X$ such that $q_{ab} \cap {\ppref} = \emptyset$: 
	\begin{equation}P(a > b \knowing {\ppref}) = \frac{1 + {\ppref^{-1}}(b)}{1 + {\ppref^{-1}}(b) + 1 + {\ppref}(b)}.\end{equation}
	In particular, it is independent of the relative ordering of the elements below $b$.
	\footnote{This is also equal to:
		\begin{equation}P(a > b \knowing {\ppref}) = \frac{(1 + {\ppref^{-1}}(b))! {\ppref}(b)!}{(1 + {\ppref^{-1}}(b))! {\ppref}(b)! + {\ppref^{-1}}(b)! (1 + {\ppref}(b))!}.\end{equation} 
	}
\end{proposition}
\begin{proof}
	Assume some set $E \subseteq \powerset{\linors}$ is such that $\cup E$ is a sure event,  for any two elements $e, e' \in E$, $e \cap e' = \emptyset$, and for any two elements $e, e' \in E$: $\set{{\ppref} \subseteq {\ppref'} \in e \suchthat a \ppref' b}$ is in bijection with $\set{{\ppref} \subseteq {\ppref'} \in e' \suchthat a \ppref' b}$, and $\set{{\ppref} \subseteq {\ppref'} \in e}$ is in bijection with $\set{{\ppref} \subseteq {\ppref'} \in e'}$. It follows that $P(e \knowing {\ppref}) = P(e' \knowing {\ppref})$ and that $P(a > b \knowing {\ppref}, e) = P(a > b \knowing {\ppref}, e')$.
	
	Thus:
	$P(a > b \knowing {\ppref}) = \sum_{e \in E} P(a > b \knowing {\ppref}, e) P(e \knowing \ppref)$, 
	and with any $e \in E$: 
	$P(a > b \knowing {\ppref}) = \card{E} P(a > b \knowing {\ppref}, e) \frac{1}{\card{E}} = P(a > b \knowing {\ppref}, e)$.
	
	This shows that we can fix (as $e$) the relative ordering of the elements above $b$, and of the elements below $b$.
	The result now follows from $P(a > b \knowing {\ppref}) = \frac{P(a > b, {\ppref}, e)}{P({\ppref}, e)} = \frac{P(a > b, {\ppref}, e)}{P(a > b, {\ppref}, e) + P(b > a, {\ppref}, e)}$.
\end{proof}

\begin{proof} Another proof. I replace $a$ by $d$ in the Proposition. We try to assess $P(d > b \knowing {\ppref})$. We have that $X'= A \cup \set{b} \cup C$, where $A = {\ppref^{-1}}(b)$, $C = {\ppref}(b)$ and $\restr{{\ppref}}{A} = \emptyset = \restr{{\ppref}}{C}$.
By \cref{th:probaPartialOrder}, we have:
\begin{equation}
	P({\ppref}) = \frac{|\set{{\ppref'} \in \linors[X']: {\ppref'} \supseteq {\ppref}}|}{|X'|!} = \frac{|A|! \cdot |C|!}{(|A|+|C|+1)!}
\end{equation}
and, by applying \cref{th:probaPartialOrder} to $X^{\prime\prime} = X' \cup \set{d}$, 
\begin{equation}
	P\big(T({\ppref} \cup \set{(d,b)})\big) = \frac{|A|! \cdot |C|! \cdot (|A|+1)}{(|A|+|C|+2)!}. 
\end{equation}
We thus have:
\begin{equation}
	P(d \ppref b \knowing {\ppref}) = \frac{P\big(T({\ppref} \cup \set{(d,b)})\big)}{P({\ppref})} = \frac{|A|+1}{|A|+|C|+2}. 
\end{equation}
\end{proof}

\begin{proposition}\label{th:Pd>a}
Let $X' \subseteq X$, ${\ppref} \in \POs[X']$ with a single connected component containing only a set $A$ of incomparable elements better than $b$ and a set $C$ o incomparable elements worse than $b$, and $d \in X$ such that $q_{bd} \cap {\ppref} = \emptyset$. For all $a \in A$: 
	\begin{equation}P(d > a \knowing {\ppref}) = \frac{(|A| + 1)/2 }{|A| + |C| +2}.\end{equation}    
\end{proposition}

\begin{proof}
We first compute $P((d,a) \cup \ppref)$. We have:
$$
P((d,a) \cup \ppref) = \frac{|C|! \ [1+2+ \ldots + |A|] \ (|A|-1)!}{(|A| + |C| +2)!}=\frac{|C|!\ (|A|(|A|+1)/2)\  (|A|-1)!}{(|A| + |C| +2)!}.
$$
We obtain this by counting the number of possible positions for $d$ when $a$ has rank 1, 2, \ldots $|A|$ in $A$. 

Therefore, using the formula for $P(\ppref)$ obtained above, we get:
$$
P((d,a) \cup \ppref|\ppref) = \frac{P((d,a) \cup \ppref)}{P(\ppref)} = \frac{(|A|+1)}{2 (|A|+ |C| + 2)}.
$$
\end{proof}

A similar expression can be obtained for $
P((c,d) \cup \ppref| \ppref)$, for any $c \in C$.

\subsection{Should we always exploit the median?}
We might attempt to answer analytically the following question: should we always ask $b$ VS everything else when we know a chain $abc$? Thus, when $\prefeq$ includes $abc$, and $q_{be}$, $q_{bf}$, … has been answered, should we ask $q_{bg}$? (That’s what every optimal strategy that we found do.) It’s a bit strange that it seems not optimal to systematically strive for a chain of three (see $k = 5$).

\begin{conjecture}
Assume $\ppref$ has a single connected component, and the maximal size of a chain is 3. Assume $b$ is the middle element of every chain of size 3. Then the optimal strategy asks $b$ with a new element.
\end{conjecture}
I’d say this is probably true but difficult to prove because of the complicated shapes such as ${abc, be, dc}$. Let’s start with something simpler.

\begin{proposition}[Better wording?]
Let $X' \subseteq X$, ${\ppref} \in \POs[X']$ with a single connected component containing only a non-empty set $A$ of incomparable elements better than $b$ and a non-empty set $C$ of incomparable elements worse than $b$, and $z \not \in X'$. The expected gain in the number of edges is maximal when asking $q_{bz}$. Using the notations of \cref{sec:optDef}, $q_{bz} \in \hat{q}({\ppref}) = \argmax_{q \in Q} E[g^{q, {\ppref}} \knowing {\ppref}]$.
\end{proposition}
\begin{proof}
	Consider any $a \in A$, $c \in C$.
	Define $\alpha = \card{A}$ and $\gamma = \card{C}$.
	\begin{equation}
		E[g^{q_{az}, {\ppref}} \knowing {\ppref}] = P(z \ppref a \knowing {\ppref}) (\gamma + 1),
	\end{equation}
	\begin{equation}
		E[g^{q_{bz}, {\ppref}} \knowing {\ppref}] = P(z \ppref b \knowing {\ppref}) \gamma + P(b \ppref z \knowing {\ppref}) \alpha.
	\end{equation}
	Thus, we need to prove:
	\begin{equation}
		P(z \ppref b \knowing {\ppref}) \gamma + P(b \ppref z \knowing {\ppref}) \alpha > P(z \ppref a \knowing {\ppref}) \gamma + P(z \ppref a \knowing >),
	\end{equation}
	or equivalently:
	\begin{equation}
		[P(z \ppref b \knowing {\ppref}) - P(z \ppref a \knowing {\ppref})] \gamma > P(z \ppref a \knowing {\ppref}) - P(b \ppref z \knowing {\ppref}) \alpha.
	\end{equation}
	
	To compute $P(z \ppref a \knowing {\ppref})$, we decompose according to $\card{\restr{{\prefeqinv}}{X'}(a)}$, the rank of $a$ in the linear completion of $\ppref$ to $X'$: 
	\begin{equation}
	P(z \ppref a \knowing \ppref, \card{\restr{{\prefeqinv}}{X'}(a)} = r) = \frac{r}{\alpha + 2 + \gamma}.
	\end{equation}
	
	As the possible ranks of $a$ range equiprobably from $1$ to $\alpha$, we obtain:
	\begin{equation}
		P(z \ppref a \knowing \ppref) = \frac{(1 + \alpha) / 2}{\alpha + 2 + \gamma}.
	\end{equation}

	On the other hand:
	\begin{equation}
		P(z \ppref b \knowing \ppref) = \frac{1 + \alpha}{\alpha + 2 + \gamma}.
	\end{equation}
	
	Thus, $P(z \ppref b \knowing \ppref) = 2 P(z \ppref a \knowing \ppref)$, 
	and the inequality holds.
	\footnote{More intuitively: $P(z \ppref a) = P(a \ppref z \ppref b)$, by symmetry.}
\end{proof}

\begin{proof}[Marc]
We have that 
$$
\Delta Eg(xy|\ppref) = \Delta g(xy|\ppref) P((x,y) |\ppref) + \Delta g(yx|\ppref) P((y,x) |\ppref).
$$

\noindent We first compute  $\Delta Eg(bd|\ppref)$ using \cref{th:indep}. We have:

\medskip
\begin{align}
\Delta Eg(bd|\ppref) &= \Delta g(bd|\ppref) P((b,d) |\ppref) + \Delta g(db|\ppref) P((d,b) |\ppref)\\
&= [1 \cdot (|C|+1) + (1+|C|) (|A|+1)]/(|A|+ |C| +2)\\
&= \frac{2 |C| + 2 + |A| + |A|\cdot|C|}{|A|+|C|+2}.
\end{align}

\bigskip
\noindent We compute $\Delta Eg(ad|\ppref)$ using \cref{th:Pd>a}. We have:

\medskip
\begin{align}
\Delta Eg(ad|\ppref) &= \Delta g(ad|\ppref) P((a,d) |\ppref) + \Delta g(da|\ppref) P((d,a) |\ppref)\\
&= [1 \cdot (|A|/2 + |C|+3/2) + (2+|C|)\cdot (|A|+1)/2]/(|A|+ |C| +2)\\
&= \frac{3 |C| + 5 + 3|A| + |A|\cdot|C|}{2 \cdot (|A|+|C|+2)}.
\end{align}

\bigskip
\noindent 
\begin{align}
\Delta Eg(ad|\ppref) - \Delta Eg(bd|\ppref) &= \frac{3 |C| + 5 + 3|A| + |A|\cdot|C| - 4 |C| - 4 -2 |A| - 2|A|\cdot|C|}{2 \cdot (|A|+|C|+2)} \\
&= |A|+1 - |C|(|A|+1).
\end{align}

The latter is non-positive as soon as $|C| \geq 1$.

\bigskip
\noindent Similarly $\Delta Eg(cd|\ppref) - \Delta Eg(bd|\ppref)$ is non-positive as soon as $|A| \geq 1$.

\bigskip
\noindent In case we ask a question $q_{de}$ for $d,e \notin X'$, the expected gain is 1 and it is not as good as with the other options. 
\end{proof}

\begin{conjecture}
	Assume > has a single connected component, and every undirected path has at most three objects. Assume $b$ is the middle element of every chain of size 3, and some element $f$ is not part of the component. Then asking $q_{bf}$ is an optimal strategy.
\end{conjecture}
\begin{proof}
	Given ${\ppref}$ as in the claim and a questioning strategy $s'$, let ${\ppref}_k^{s'}$ designate the “random variable” that represents our (increased) knowledge after $k$ questions following $s'$;
	let $g(q, {\ppref}_k^{s'})$ designate the random variable that represents the gain of asking $q$ knowing ${\ppref}_k^{s'}$.
	
	Consider any $s'$, $a \in X$, $k ≥ 0$.
	Our theorem is:
	$E[g(q_{az}, {\ppref}_k^{s'}) \knowing {\ppref}] ≤ E[g(q_{bz}, {\ppref}_k^{s}) \knowing {\ppref}]$.
	
	Let $A = \card{{\pprefinv}(b)}$, $C = \card{{\ppref}(b)}$, $l = A + C$, $A_k = \card{({\ppref}_k^{s})^{-1}(b)}$, $C_k = \card{{\ppref}_k^{s}(b)}$, $A'_k = \card{({\ppref}_k^{s'})^{-1}(a)}$, $C'_k = \card{{\ppref}_k^{s'}(a)}$. The latter four are random variables.

	First, consider a strategy $s'$ such that $P(A'_k + C'_k = k + l) = 1$: it “wastes no edge”.

	To any $0 ≤ d ≤ k + l$, associate to the set $S'_d = \set{{\ppref}_k^{s'} \suchthat A'_k + C'_k = k + l, \abs{A'_k - C'_k} = d}$ the set $S_d = \set{{\ppref}_k^{s} \suchthat A_k + C_k = k + l, \abs{A_k - C_k} = d}$, and to the set $S'_{≤d} = \cup_{0 ≤ d' ≤ d} S'_d = \set{{\ppref}_k^{s'} \suchthat A'_k + C'_k = k + l, \abs{A'_k - C'_k} ≤ d}$ the set $S_{≤d} = \cup_{0 ≤ d' ≤ d} S_d = \set{{\ppref}_k^{s} \suchthat A_k + C_k = k + l, \abs{A_k - C_k} ≤ d}$.
	
	We now need to prove two claims. First, $\forall 0 ≤ d ≤ k + l, {\ppref}_k^{s'} \in S'_d, {\ppref}_k^{s} \in S_d: E[g(q_{az}, {\ppref}_k^{s'}) \knowing {\ppref}] ≤ E[g(q_{bz}, {\ppref}_k^{s}) \knowing {\ppref}]$. 
	Second, $P(S_d) ≥ P(S'_d)$.
	I believe both can be proven with not much difficulty.
	
	Then, consider a strategy $s'$ such that $P(A'_k + C'_k < k + l) > 0$. I believe we can prove that there exists a similar strategy $t$ that has a better average $A'_k + C'_k$ and that has a better expected gain (thus $E[g(q_{az}, {\ppref}_k^{s'}) \knowing {\ppref}] ≤ E[g(q_{az}, {\ppref}_k^{t}) \knowing {\ppref}]$). 
	That is because $s'$ supports asking some question $q_{xy}$ not related to $a$ ($x ≠ a$ and $y ≠ a$). Build $t$ by replacing one of these questions with a question about $a$ ($q_{ax}$ or $q_{ay}$). This can only improve the expected gain. 
	
	This proves the claim for all strategies.
	
	Note that this fails because it might be that $E^{s'}[g(q_a)]$ is bad in general, but  $E^{s'}[g(q_a)]$ is good precisely when $a$ is the best question. We need to count $E^{s'}$ as $P(q_a best) E[g(q_a) \knowing q_a best] + …$.
	
	(Idea: Construisions un tout nouveau sablier car on est sûr que celui-là sera équilibré. De manière certaine, construire un sablier avec 2 éléments meilleurs et 2 moins bons, et puis l’exploiter avec beaucoup de questions.)
	
	\commentOC{TODO Cardinal A est Alpha et de C est gamma.}
	
	New attempt.
	
	Say that $s$ dominates $s'$ in (sum, balance) iff $\forall (k, d): $ prob $s$ to have (sum, bal) $≥ (k, -d)$ is at least prob $s'$ to have (sum, bal) $≥ (k, -d)$.
	
	Prove that this property persists to the next question.
	
	Prove that when $s$ dominates $s'$ in that sense, $s$ is better in terms of expected gain.
\end{proof}
\begin{proof}[New]
	Consider $P({\ppref})$ and $R({\ppref})$, two probability distributions over $\POs$.
	Given ${\ppref} \in \POs$ and $a, z \in X$, define $\zeta({\ppref}, a, z) \in \R^6$ as the vector $(s, -d, m, s', -d', m')$ representing the potential of $a$ after $q_{az}$, namely, $s = (above a + below z) + (below a + above z)$, $d = \abs{(above a + below z) - (below a + above z)}$, $m = prob of answer that maximizes gain thus a > z if (above a + below z) is higher$, $d' = (above a + above z) - (below a)$, $d^{\prime\prime} = (below a + below z) - (above a)$, $m' = prob of answer that maximizes balance…$, and still more indicators.
	
	As this is complicated, let’s focus on strategies that ask only questions involving at least one new object.
\end{proof}

Notation: when the relevant partial order ${\ppref} \in \POs$ is clearly indicated by the context, we omit it from the notations of the strict upper and lower countour sets and represent the strict upper and lower contour sets of $a \in \allalts$ with $\upa = {\pprefinv}(a)$ and $\downa = {\ppref}(a)$.
\begin{proof}[Newer]
	Given ${\ppref} \in \POs$ and $a \in \allalts$, define $\zeta({\ppref}, a) \in \R^2$ as the vector $(s, -d)$ representing the potential of a question involving $a$ in $\ppref$, namely, $s = (\upa + \downa)$ and $d = \abs{\upa - \downa}$.
	Define the potential of ${\ppref}$ as $\zeta({\ppref}) = \max_{a \in \allalts} \zeta({\ppref}, a)$.
	
	Given $(s, -d)$, the preorders with potential $(s, -d)$ are thus $\zeta^{-1}((s, -d))$. We denote the preorders with potential at least $(s, -d)$ as $\zeta^{-1}({\uparrow}(s, -d)) = \set{{\ppref} \in \POs \suchthat \max_{a \in \allalts} \zeta({\ppref}, a) ≥ (s, -d)}$, where $≥$ denote the vector dominance relation in $\R^2$, thus, $(s, -d) ≥ (s', -d') ⇔ s ≥ s' \land -d ≥ -d'$.
	
	Equivalently, we can represent the potential $(s, -d)$ by $(m = \min(\upa, \downa) = \frac{s - d}{2}, M = \max(\upa, \downa) = \frac{s + d}{2})$.
	
	Given two probability distributions $R$ and $S$ over $\POs$, say that $R$ dominates $S$ iff $\forall s, d \in \N$: 
	\begin{equation}
		R(\zeta^{-1}({\uparrow}(s, -d))) ≥ S(\zeta^{-1}({\uparrow}(s, -d))).
	\end{equation}
	
	We now want to prove two things. 
	First, if $R$ dominates $S$, it yields a higher gain.
	Second, the dominance persists to the next question: if $R$ dominates $S$, then for any question $q$ (involving at least one new object), there exists $q'$ such that $R + q'$ still dominates $S + q$.
	
	Then, we want to show that $abc$ with $q_{bz}$ dominates $abc$ with $q_{az}$, and extend this claim suitably.
	
	Note that $g$, understood as in \cref{sec:optDef} as $g({\ppref}) = \max_q E[g^{q, {\ppref}} \knowing {\ppref}]$, is a random variable wrt a probability distribution over the partial orders $\POs$.
	
	Given ${\ppref} \in \POs$ and $a \in \allalts$ with potential $\zeta({\ppref}, a) = (s, -d)$, a question $q_{az}$ yields as expected gain $E[g^{q_{az}, {\ppref}} \knowing {\ppref}] = p \frac{s + d}{2} + (1 - p) \frac{s - d}{2}$, where $p$ is the probability of a favorable answer to the question, that is, one that yields a gain of $\max(\upa, \downa)$; and $1 - p$ is the probability of an answer that yields a gain of $\min(\upa, \downa)$.
	
	Hopefully, for any ${\ppref} \in \POs$ and $a \in \allalts$ with potential $\zeta({\ppref}, a) = (s, -d)$ and ${\ppref'} \in \POs$ and $a' \in \allalts$ with potential $\zeta({\ppref'}, a') = (s', -d') < (s, -d)$, $E[g^{q_{az}, {\ppref}} \knowing {\ppref}] ≥ E[g^{q_{a'z}, {\ppref'}} \knowing {\ppref'}]$. That is, increasing the sum or decreasing the difference never hurts the expected gain. (A partial justification for this bold claim is that I think that $p$ decreases rapidly when the difference increases.)
	
	A preorder ${\ppref}$ with potential $\zeta({\ppref}) = (s, -d)$ therefore has a not lower gain $g({\ppref})$ than another preorder ${\ppref'}$ with lower potential $\zeta({\ppref'}) = (s', d') < (s, -d)$.
	
	It follows that if $R$ dominates $S$, $E_R[g] ≥ E_S[g]$.
	
	Given a distribution $R$, define $R + q$ as the expected distribution resulting from adding the answer to $q$ (given by the distribution $P$), computed before knowing the answer. $(R + q)({\ppref'}) = \sum_{{\ppref}, {\pref} \suchthat {\ppref'} = T({\ppref} \cup (q \cap {\pref}))} R({\ppref}) P({\pref})$.
	
	Our second claim is that if $R$ dominates $S$, then $\forall q \in Q, \exists q' \in Q \suchthat R + q' \text{ dominates } S + q$.
	
	I believe this is true because if some $q$ permits to increase the probability of the potential $(s, -d)$ from $S$, then it has taken those having lower potential $p'$ with prob $S(p')$ and added edges to it; but the prob $R(p')$ was higher and the possible gains are higher as well.
	$(S + q)(\zeta^{-1}(m', M')) = \sum_{M < M'} S(\zeta^{-1}(m', M)) × (\text{Prob. best gained at least } M' - M) + …$
\end{proof}
	
\begin{remark}
	Let ${\ppref} = T(\set{(e, a), (a, b), (b, c)})$.
	Let’s compare the expected gains of $q_{az}$ for ${\ppref_a} = T({\ppref} \cup \set{(a, g)})$ and for ${\ppref_b} = T({\ppref} \cup \set{(g, b)})$.
	Let $E_a = E[g(q_{az}, {\ppref_a}) \knowing {\ppref_a}]$,
	$E_b = E[g(q_{az}, {\ppref_b}) \knowing {\ppref_b}]$.
	
	We want to prove that having $(a, g)$ is better. 
	Thus: $E_a > E_b$.
	
	$E_a = P(b \pref g \knowing {\ppref_a}) E[g(q_{az}, {\ppref_a}) \knowing {\ppref_a}, (b, g)] + P(g \pref b \knowing {\ppref_a}) E[g(q_{az}, {\ppref_a}) \knowing {\ppref_a}, (g, b)]$.
	
	$E_a = \frac{2}{3} [\frac{2}{6} 3 + \frac{4}{6} 1] + \frac{1}{3} [\frac{2}{6} 3 + \frac{4}{6} 1] = \frac{2}{6} 3 + \frac{4}{6} 1 = \frac{10}{6} = \frac{30}{18}$.
	
	$E_b = P(a \pref g \knowing {\ppref_b}) E[g(q_{az}, {\ppref_b}) \knowing {\ppref_b}, (a, g)] + P(g \pref a \knowing {\ppref_b}) E[g(q_{az}, {\ppref_b}) \knowing {\ppref_b}, (g, a)]$.
	
	$E_b = \frac{1}{3} [\frac{2}{6} 2 + \frac{4}{6} 1] + \frac{2}{3} [\frac{3}{6} 1 + \frac{3}{6} 2] = \frac{1}{3} \frac{8}{6} + \frac{2}{3} \frac{9}{6} = \frac{26}{18}$.
\end{remark}

\begin{remark}
	It may be thought that in every configurations where $b$ is in the middle of every paths of length 3, with no paths of length more than 3 and at least one path of length 3, it holds that asking about $b$ is best. This is likely false. 
	
	Let $a \ppref b$, $A = {\pprefinv}(b)$, $C = {\ppref}(b)$, $S = {\ppref}(a) \setminus \set{b} \setminus C$.
	
	Computing $P(f > b \knowing {\ppref})$ seems difficult, but hopefully we do not overestimate it too badly by forgetting that $a \ppref S$. Then, $P(f > b \knowing {\ppref} \setminus \cup_{s \in S} (a, s)) = \frac{1 + \alpha}{2 + \alpha + \gamma}$, and the complement is $\frac{1 + \gamma}{2 + \alpha + \gamma}$.
	
	With the approximation $P(f > b \knowing {\ppref}) \sim P(f > b \knowing {\ppref} \setminus \cup_{s \in S} (a, s))$, we obtain as approximate gain for $q_{bf}$:
	\begin{equation}
		\frac{1 + \alpha}{2 + \alpha + \gamma} \gamma + \frac{1 + \gamma}{2 + \alpha + \gamma} \alpha = \frac{\gamma + 2 \alpha \gamma + \alpha}{2 + \alpha + \gamma}.
	\end{equation}
	The gain for $q_{af}$ is, very approximately:
	\begin{equation}
		\frac{(1 + \alpha) / 2}{1 + \alpha + \card{S} + 1 + \gamma} (\card{S} + 1 + \gamma) = \frac{\card{S} + 1 + \gamma + \alpha \card{S} + \alpha + \alpha \gamma}{2 (2 + \alpha + \card{S} + \gamma)}.
	\end{equation}
	With $\alpha = \card{S}$ and $\gamma = 1$, this yields approximate gains for $q_{bf}$ of $\frac{1 + 3 \alpha}{3 + \alpha}$ and for $q_{af}$ of $\frac{3 \alpha + 2 + \alpha^2}{6 + 4 \alpha}$. 
	
	Under these approximations, for $\alpha = 7$, the inequality still holds ($22/10 > 72/34$); it fails from $\alpha = 8$ onwards.
\end{remark}

\newlength{\ordown}
\setlength{\ordown}{2mm}
\begin{figure}
	\begin{tikzpicture}
		\path node (ab-a) {$a$};
		\path (ab-a.south) ++(0, -\ordown) node[anchor=north] (ab-b) {$b$};
		\path [draw] (ab-a) -- (ab-b);
		
		\path (ab-b.south) ++(-2cm, -1cm) coordinate (abc);
		\path (abc) node[anchor=north] (abc-a) {$a$};
		\path (abc-a.south) ++(0, -\ordown) node[anchor=north] (abc-b) {$b$};
		\path (abc-b.south) ++(0, -\ordown) node[anchor=north] (abc-c) {$c$};
		\path [draw] (abc-a) -- (abc-b) -- (abc-c);
		\path [draw, color=red] (abc-a) to[out=-45, in=45] (abc-c);

		\path (ab-b.south) ++(2cm, -1cm) coordinate (ab-cb);
		\path (ab-cb) ++(-3mm, -\ordown) node[anchor=north] (ab-cb-a) {$a$};
		\path (ab-cb-a.south) ++(3mm, -\ordown) node[anchor=north] (ab-cb-b) {$b$};
		\path (ab-cb-a.south) ++(6mm, 0) node[anchor=south] (ab-cb-c) {$c$};
		\path [draw] (ab-cb-a) -- (ab-cb-b) -- (ab-cb-c);

		\path (ab-b.south)  edge node[left, align = right] {$b > c$\\\tiny P(bc \knowing ab) = 1/3} (abc);
		\path (ab-b.south) edge node[above right] {$c > b$} (ab-cb);

		\path (abc-c.south) ++(-1cm, -1cm) coordinate (abc-bd);
		\path (abc-bd) node[anchor=north] (abc-bd-a) {$a$};
		\path (abc-bd-a.south) ++(0, -\ordown) node[anchor=north] (abc-bd-b) {$b$};
		\path (abc-bd-b.south) ++(-3mm, -\ordown) node[anchor=north] (abc-bd-c) {$c$};
		\path (abc-bd-c.base) ++(6mm, 0) node[anchor=base, inner sep=2pt] (abc-bd-d) {$d$};
		\path [draw] (abc-bd-a) -- (abc-bd-b) -- (abc-bd-c);
		\path [draw] (abc-bd-b) -- (abc-bd-d);
		\path [draw, color=red] (abc-bd-a) to[out=-45, in=45] (abc-bd-d);

		\path (abc-c.south) ++(1cm, -1cm) coordinate (abc-db);
		\path (abc-db) ++(-3mm, 0) node[anchor=north] (abc-db-a) {$a$};
		\path (abc-db-a.south) ++(3mm, -\ordown) node[anchor=north] (abc-db-b) {$b$};
		\path (abc-db-b.south) ++(0, -\ordown) node[anchor=north] (abc-db-c) {$c$};
		\path (abc-db-a.south) ++(6mm, 0) node[anchor=south] (abc-db-d) {$d$};
		\path [draw] (abc-db-a) -- (abc-db-b) -- (abc-db-c);
		\path [draw] (abc-db-d) -- (abc-db-b);
		\path [draw, color=red] (abc-db-d) to[out=-45, in=45] (abc-db-c);

		\path (abc-c.south)  edge node[above left] {$b > d$} (abc-bd);
		\path (abc-c.south) edge node[above right] {$d > b$} (abc-db);
		
		\path (abc-c.south -| ab-cb-b) coordinate (ab-cb-south);
		\path (ab-cb-south) ++(-1cm, -1cm) coordinate (abd-cb);
		\path (abd-cb) ++(-3mm, 0) node[anchor=north] (abd-cb-a) {$a$};
		\path (abd-cb-a.south) ++(3mm, -\ordown) node[anchor=north] (abd-cb-b) {$b$};
		\path (abd-cb-a.south) ++(6mm, 0) node[anchor=south] (abd-cb-c) {$c$};
		\path (abd-cb-b.south) ++(0, -\ordown) node[anchor=north] (abd-cb-d) {$d$};
		\path [draw] (abd-cb-a) -- (abd-cb-b) -- (abd-cb-d);
		\path [draw] (abd-cb-c) -- (abd-cb-b);
		\path [draw, color=red] (abd-cb-a) to[out=-110, in=135] (abd-cb-d);
		\path [draw, color=red] (abd-cb-c) to[out=-70, in=45] (abd-cb-d);

		\path (ab-cb-south) ++(1cm, -1cm) coordinate (ab-cb-db);
		\path (ab-cb-db) ++(-4mm, 0) node[anchor=north] (ab-cb-db-a) {$a$};
		\path (ab-cb-db-a.south) ++(4mm, -\ordown) node[anchor=north] (ab-cb-db-b) {$b$};
		\path (ab-cb-db-a.base) ++(4mm, 0) node[anchor=base] (ab-cb-db-c) {$c$};
		\path (ab-cb-db-c.base) ++(4mm, 0) node[anchor=base] (ab-cb-db-d) {$d$};
		\path [draw] (ab-cb-db-a) -- (ab-cb-db-b);
		\path [draw] (ab-cb-db-c) -- (ab-cb-db-b);
		\path [draw] (ab-cb-db-d) -- (ab-cb-db-b);

		\path (ab-cb-south)  edge node[left, align=right] {$b > d$\\\tiny $P(bd \knowing ab, cb) = 1/4$} (abd-cb);
		\path (ab-cb-south) edge node[above right] {$d > b$} (ab-cb-db);		
	\end{tikzpicture}
	\caption{The “connected” optimal strategy for three questions}
	\label{fig:k3a}
\end{figure}
\begin{figure}
	\begin{tikzpicture}
		\path node (ab-a) {$a$};
		\path (ab-a.south) ++(0, -\ordown) node[anchor=north] (ab-b) {$b$};
		\path [draw] (ab-a) -- (ab-b);
		
		\path (ab-b.south) ++(-1cm, -1cm) coordinate (ab-cd);
		\path (ab-cd) ++(-3mm, -\ordown) node[anchor=north] (ab-cd-a) {$a$};
		\path (ab-cd-a.south) ++(0, -\ordown) node[anchor=north] (ab-cd-b) {$b$};
		\path (ab-cd-a.base) ++(6mm, 0) node[anchor=base] (ab-cd-c) {$c$};
		\path (ab-cd-c.south) ++(0, -\ordown) node[anchor=north] (ab-cd-d) {$d$};
		\path [draw] (ab-cd-a) -- (ab-cd-b);
		\path [draw] (ab-cd-c) -- (ab-cd-d);

		\path (ab-b.south) ++(1cm, -1cm) coordinate (ab-dc);

		\path (ab-b.south)  edge node[above left] {$c > d$} (ab-cd);
		\path (ab-b.south)  edge node[above right] {$d > c$} (ab-dc);

		\path node [fit={(ab-cd-a) (ab-cd-d)}] (ab-cd-node) {};
		
		\path (ab-cd-node.south) ++(-1cm, -1cm) coordinate (ab-acd);
		\path (ab-acd) node[anchor=north] (ab-acd-a) {$a$};
		\path (ab-acd-a.south) ++(-3mm, -\ordown - 3mm) node[anchor=base, inner sep=0] (ab-acd-b) {$b$};
		\path (ab-acd-a.south) ++(3mm, -\ordown - 3mm) node[anchor=base] (ab-acd-c) {$c$};
		\path (ab-acd-c.south) ++(0, -\ordown) node[anchor=north] (ab-acd-d) {$d$};
		\path [draw] (ab-acd-a) -- (ab-acd-b);
		\path [draw] (ab-acd-a) -- (ab-acd-c) -- (ab-acd-d);
		\path [draw, color=red] (ab-acd-a) to[out=-30, in=45] (ab-acd-d);

		\path (ab-cd-node.south) ++(1cm, -1cm) coordinate (cab-cd);

		\path (ab-cd-node.south)  edge node[above left] {$a > c$} (ab-acd);
		\path (ab-cd-node.south)  edge node[above right] {$c > a$} (cab-cd);
	\end{tikzpicture}
	\caption{The “disconnecting” optimal strategy for three questions}
	\label{fig:k3b}
\end{figure}

\subsection{Optimal strategies for 3 questions}
Consider $n ≥ 4$ and let us determine the strategies that maximize the expected number of edges known after $3$ questions, thus, $E^s[\card{{\ppref}_3}]$.

We write $cd$ instead of $\set{(c, d)}$, $abc$ instead of $\set{(a, b), (b, c), (a, c)}$, and so on.

The following computations (assuming $P = P^\text{eq}$ and independent of $s$) show that there are two tied optimal strategies (plus the obvious symmetries). One optimal strategy, after $q_{ab}$, asks about $q_{cd}$, then joins the two disconnected components by asking about the top ones of each component; and the other one, after $q_{ab}$, asks about $q_{bc}$, then, if obtaining a linear order over $\set{a, b, c}$, asks about the median one and $d$, and otherwise, asks about the one connected to the two other ones and $d$.
\begin{itemize}
	\item $E[\card{{\ppref}_3} - \card{{\ppref}_2} - 1 \knowing {\ppref}_2 = abc, q_3 = q_{cd}] = 1/2$. {\tiny $P(cd \knowing abc) = \frac{P(abcd)}{P(abc)} = \frac{3!}{4!} = 1/4$. Edges gained if $cd$: 2. Otherwise: 0.}
	\item $E[\card{{\ppref}_3} - \card{{\ppref}_2} - 1 \knowing {\ppref}_2 = abc, q_3 = \bm{q_{bd}}] = 1$.
	\item $E[\card{{\ppref}_3} - \card{{\ppref}_2} - 1 \knowing {\ppref}_2 = \set{ab, cb}, q_3 = \bm{q_{bd}}] = 1/2$. {\tiny $P(bd \knowing ab, cb) = P(ac \knowing ab, cb) P(bd \knowing acb) + P(ca \knowing ab, cb) P(bd \knowing cab) = 1/2 P(bd \knowing acb) + 1/2 P(bd \knowing cab) = 1/4$. Gain: $2$. Otherwise, gain: $0$.}
	\item $E[\card{{\ppref}_3} - \card{{\ppref}_2} - 1 \knowing {\ppref}_2 = \set{ab, cb}, q_3 = q_{da}] = 3/8$. {\tiny $P(da \knowing ab, cb) = 1/2 P(da \knowing acb) + 1/2 P(da \knowing cab) = 1/2 P(dacb \knowing acb) + 1/2 P(dab, cab \knowing cab) = 1/2 (1/4) + 1/2 (2/4) = 3/8$. Gain if $da$: $1$. Otherwise: $0$.}
	\item $E[\card{{\ppref}_3} - \card{{\ppref}_2} - 1 \knowing {\ppref}_2 = \set{ab, cb}, q_3 = q_{ac}] = 0$.
	\item $E[\card{{\ppref}_3} - \card{{\ppref}_2} - 1 \knowing {\ppref}_2 = \set{ab, cd}, q_3 = q_{da}] = 1/2$. {\tiny $P(da \knowing ab, cd) = P(cdab \knowing ab, cd) = \frac{4}{4!} = 1/6$. Gain if $da$: $3$. Otherwise: $0$.}
	\item $E[\card{{\ppref}_3} - \card{{\ppref}_2} - 1 \knowing {\ppref}_2 = \set{ab, cd}, q_3 = \bm{q_{ac}}] = 1$.
	\item $E^s[\card{{\ppref}_3} - \card{{\ppref}_1} - 2 \knowing {\ppref}_1 = ab, q_2 = \bm{q_{cd}}] = 1$.
	\item $E^s[\card{{\ppref}_3} - \card{{\ppref}_1} - 2 \knowing {\ppref}_1 = ab, q_2 = \bm{q_{bc}}] = 1$. {\tiny $P(bc \knowing ab) = \frac{2!}{3!} = 1/3$. Immediate gain if $bc$: $1$. $E$ total gain if $bc$: $2$. Otherwise, immediate gain is $0$ and total gain is $1/2$. Thus, $E$ total gain: $1/3 × 2 + 2/3 × 1/2 = 1$.}
\end{itemize}

See \cref{fig:k3a,fig:k3b}.

\subsection{Optimum for 4 questions}
Computer experiments show that the following is the strategy that maximizes $E^s[\card{{\ppref}_4}]$ (assuming $n ≥ 5$). 
Start by using two questions to order $\set{a, b, c}$. If ${\ppref}_2$ is a linear order (say, $abc$), spend the remaining two questions by comparing yet unknown elements with $b$. Otherwise (say, $\set{a, c} \ppref b$), disconnect temporarily by asking $q_{de}$ (say, $de$), then connect the two components by asking $q_{be}$.

See \cref{fig:k4}.

\begin{figure}
	\begin{tikzpicture}
		\path node (ab-a) {$a$};
		\path (ab-a.south) ++(0, -\ordown) node[anchor=north] (ab-b) {$b$};
		\path [draw] (ab-a) -- (ab-b);
		
		\path (ab-b.south) ++(-4cm, -1cm) coordinate (abc);
		\path (abc) node[anchor=north] (abc-a) {$a$};
		\path (abc-a.south) ++(0, -\ordown) node[anchor=north] (abc-b) {$b$};
		\path (abc-b.south) ++(0, -\ordown) node[anchor=north] (abc-c) {$c$};
		\path [draw] (abc-a) -- (abc-b) -- (abc-c);
		\path [draw, color=red] (abc-a) to[out=-45, in=45] (abc-c);

		\path (ab-b.south) ++(4cm, -1cm) coordinate (ab-cb);
		\path (ab-cb) ++(-3mm, -\ordown) node[anchor=north] (ab-cb-a) {$a$};
		\path (ab-cb-a.south) ++(3mm, -\ordown) node[anchor=north] (ab-cb-b) {$b$};
		\path (ab-cb-a.south) ++(6mm, 0) node[anchor=south] (ab-cb-c) {$c$};
		\path [draw] (ab-cb-a) -- (ab-cb-b) -- (ab-cb-c);

		\path (ab-b.south)  edge node[left, align = right] {$b > c$\\\tiny P(bc \knowing ab) = 1/3} (abc);
		\path (ab-b.south) edge node[above right] {$c > b$} (ab-cb);

		\path (abc-c.south) ++(-16mm, -1cm) coordinate (abc-bd);
		\path (abc-bd) node[anchor=north] (abc-bd-a) {$a$};
		\path (abc-bd-a.south) ++(0, -\ordown) node[anchor=north] (abc-bd-b) {$b$};
		\path (abc-bd-b.south) ++(-3mm, -\ordown) node[anchor=north] (abc-bd-c) {$c$};
		\path (abc-bd-c.base) ++(6mm, 0) node[anchor=base, inner sep=2pt] (abc-bd-d) {$d$};
		\path [draw] (abc-bd-a) -- (abc-bd-b) -- (abc-bd-c);
		\path [draw] (abc-bd-b) -- (abc-bd-d);
		\path [draw, color=red] (abc-bd-a) to[out=-45, in=45] (abc-bd-d);
		\path node [fit={(abc-bd-a) (abc-bd-c) (abc-bd-d)}, inner sep=0] (abc-bd-node) {};

		\path (abc-c.south) ++(16mm, -1cm) coordinate (abc-db);
		\path (abc-db) ++(-3mm, 0) node[anchor=north] (abc-db-a) {$a$};
		\path (abc-db-a.south) ++(3mm, -\ordown) node[anchor=north] (abc-db-b) {$b$};
		\path (abc-db-b.south) ++(0, -\ordown) node[anchor=north] (abc-db-c) {$c$};
		\path (abc-db-a.south) ++(6mm, 0) node[anchor=south] (abc-db-d) {$d$};
		\path [draw] (abc-db-a) -- (abc-db-b) -- (abc-db-c);
		\path [draw] (abc-db-d) -- (abc-db-b);
		\path [draw, color=red] (abc-db-d) to[out=-45, in=45] (abc-db-c);
		\path node [fit={(abc-db-a) (abc-db-c) (abc-db-d)}, inner sep=0] (abc-db-node) {};

		\path (abc-c.south)  edge node[above left] {$b > d$} (abc-bd);
		\path (abc-c.south) edge node[above right] {$d > b$} (abc-db);
		
		\path (abc-c.south -| ab-cb-b) coordinate (ab-cb-south);
		\path (ab-cb-south) ++(-16mm, -1cm) coordinate (ab-cb-de);
		\path (ab-cb-de) ++(0, -\ordown) node[anchor=north] (ab-cb-de-c) {$c$};
		\path (ab-cb-de-c.south) ++(-6mm, 0) node[anchor=south] (ab-cb-de-a) {$a$};
		\path (ab-cb-de-a.south) ++(3mm, -\ordown) node[anchor=north] (ab-cb-de-b) {$b$};
		\path (ab-cb-de-c.base) ++(6mm, 0) node[anchor=base] (ab-cb-de-d) {$d$};
		\path (ab-cb-de-d.south) ++(0, -\ordown) node[anchor=north] (ab-cb-de-e) {$e$};
		\path [draw] (ab-cb-de-a) -- (ab-cb-de-b);
		\path [draw] (ab-cb-de-c) -- (ab-cb-de-b);
		\path [draw] (ab-cb-de-d) -- (ab-cb-de-e);
		\path (abc-db-c.south -| ab-cb-de) coordinate (ab-cb-de-south);

		\path (ab-cb-south) ++(16mm, -1cm) coordinate (ab-cb-ed);

		\path (ab-cb-south)  edge node[above left] {$d > e$} (ab-cb-de);
		\path (ab-cb-south) edge node[above right] {$e > d$} (ab-cb-ed);		
		
		\path (abc-bd-node.south) ++(-1cm, -1cm) coordinate (abc-bd-be);
		\path (abc-bd-be) node[anchor=north] (abc-bd-be-a) {$a$};
		\path (abc-bd-be-a.south) ++(0, -\ordown) node[anchor=north] (abc-bd-be-b) {$b$};
		\path (abc-bd-be-b.south) ++(-6mm, -\ordown) node[anchor=north] (abc-bd-be-c) {$c$};
		\path (abc-bd-be-c.base) ++(6mm, 0) node[anchor=base, inner sep=2pt] (abc-bd-be-d) {$d$};
		\path (abc-bd-be-c.base) ++(12mm, 0) node[anchor=base] (abc-bd-be-e) {$e$};
		\path [draw] (abc-bd-be-a) -- (abc-bd-be-b) -- (abc-bd-be-c);
		\path [draw] (abc-bd-be-b) -- (abc-bd-be-d);
		\path [draw] (abc-bd-be-b) -- (abc-bd-be-e);
		\path [draw, color=red] (abc-bd-be-a) to[out=-45, in=60] (abc-bd-be-e);
		
		\path (abc-bd-node.south) ++(1cm, -1cm) coordinate (abc-ebd);
		\path (abc-ebd) ++(-3mm, 0) node[anchor=north] (abc-ebd-a) {$a$};
		\path (abc-ebd-a.south) ++(3mm, -\ordown) node[anchor=north] (abc-ebd-b) {$b$};
		\path (abc-ebd-b.south) ++(-3mm, -\ordown) node[anchor=north] (abc-ebd-c) {$c$};
		\path (abc-ebd-c.base) ++(6mm, 0) node[anchor=base, inner sep=2pt] (abc-ebd-d) {$d$};
		\path (abc-ebd-a.base) ++(6mm, 0) node[anchor=base] (abc-ebd-e) {$e$};
		\path [draw] (abc-ebd-a) -- (abc-ebd-b) -- (abc-ebd-c);
		\path [draw] (abc-ebd-b) -- (abc-ebd-d);
		\path [draw] (abc-ebd-e) -- (abc-ebd-b);
		\path [draw, color=red] (abc-ebd-e) to[out=-90, in=60] (abc-ebd-c);
		\path [draw, color=red] (abc-ebd-e) to[out=-45, in=60] (abc-ebd-d);

		\path (abc-bd-node.south)  edge node[left] {$b > e$} (abc-bd-be);
		\path (abc-bd-node.south) edge node[right] {$e > b$} (abc-ebd);		
		
		\path (ab-cb-de-south) ++(-1cm, -1cm) coordinate (abe-cb-de);
		\path (abe-cb-de) node[anchor=north] (abe-cb-de-c) {$c$};
		\path (abe-cb-de-c.south) ++(-6mm, 0) node[anchor=south] (abe-cb-de-a) {$a$};
		\path (abe-cb-de-a.south) ++(3mm, -\ordown) node[anchor=north] (abe-cb-de-b) {$b$};
		\path (abe-cb-de-b.base) ++(6mm, 0) node[anchor=base] (abe-cb-de-d) {$d$};
		\path (abe-cb-de-b.south) ++(3mm, -\ordown) node[anchor=north] (abe-cb-de-e) {$e$};
		\path [draw] (abe-cb-de-a) -- (abe-cb-de-b) -- (abe-cb-de-e);
		\path [draw] (abe-cb-de-c) -- (abe-cb-de-b);
		\path [draw] (abe-cb-de-d) -- (abe-cb-de-e);
		\path [draw, color=red] (abe-cb-de-a) to[out = -120, in = -180] (abe-cb-de-e);
		\path [draw, color=red] (abe-cb-de-c) -- (abe-cb-de-e);

		\path (ab-cb-de-south) ++(1cm, -1cm) coordinate (ab-cb-deb);
		\path (ab-cb-deb) ++(6mm, 0) node[anchor=north] (ab-cb-deb-d) {$d$};
		\path (ab-cb-deb-d.south) ++(-6mm, -\ordown) node[anchor=north] (ab-cb-deb-c) {$c$};
		\path (ab-cb-deb-c.base) ++(-6mm, 0) node[anchor=base] (ab-cb-deb-a) {$a$};
		\path (ab-cb-deb-c.south) ++(0, -\ordown) node[anchor=north] (ab-cb-deb-b) {$b$};
		\path (ab-cb-deb-c.base) ++(6mm, 0) node[anchor=base] (ab-cb-deb-e) {$e$};
		\path [draw] (ab-cb-deb-a) -- (ab-cb-deb-b) -- (ab-cb-deb-e);
		\path [draw] (ab-cb-deb-c) -- (ab-cb-deb-b);
		\path [draw] (ab-cb-deb-d) -- (ab-cb-deb-e);
		\path [draw, color=red] (ab-cb-deb-d) -- (ab-cb-deb-b);

		\path (ab-cb-de-south)  edge node[left] {$b > e$} (abe-cb-de);
		\path (ab-cb-de-south) edge node[right] {$e > b$} (ab-cb-deb);	
	\end{tikzpicture}
	\caption{The optimal strategy for four questions}
	\label{fig:k4}
\end{figure}

\subsection{Optimum for 5 questions}
Computer experiments show that the following is the strategy that maximizes $E^s[\card{{\ppref}_5}]$ (assuming $n ≥ 6$). 
Start by using two questions to order $\set{a, b, c}$.

\begin{itemize}
	\item Assume that ${\ppref}_2$ is a linear order (say, $abc$). Then ask $q_{bd}$, $q_{be}$ and $q_{bf}$.
	\item Say, ${{\ppref}_2} = \set{a, c} \ppref b$. Then two optimal strategies follow.
	\begin{itemize}
		\item Disconnect temporarily by asking $q_{de}$ (say, $de$), then connect the two components by asking $q_{be}$. If $b > e$ then we obtain ${\ppref}_4 = \set{a, c} \ppref b \ppref e, d \ppref e$. We can exploit the chain of three elements and end up with $q_{bf}$. Otherwise, $eb$, we obtain ${{\ppref}_4} = \set{a, c} \ppref b, d \ppref e \ppref b$. We can exploit the chain of three elements and end up with $q_{ef}$. 
		\item Ask $bd$. If ${{\ppref}_3} = \set{a, c, d} > b$, disconnect; say $ef$, then $q_{bf}$. Otherwise, ${\ppref}_3 = \set{a, c} \ppref b \ppref d$, and ask $q_{be}$ then $q_{bf}$.
	\end{itemize}
\end{itemize}

\subsection{Optimum for 6 questions}
Computer experiments show that the following is the strategy that maximizes $E^s[\card{{\ppref}_6}]$ (assuming $n ≥ 7$). 
Start by using two questions to order $\set{a, b, c}$.

\begin{itemize}
	\item Assume that ${\ppref}_2$ is a linear order (say, $abc$). Then ask $q_{bd}$, $q_{be}$, $q_{bf}$ and $q_{bg}$.
	\item Say, ${\ppref}_2 = \set{a, c} \ppref b$. Then $q_{ac}$. Say, wlog: ${\ppref_3} = acb$. Then ask $q_{cd}$, $q_{ce}$ and $q_{cf}$.
\end{itemize}

\subsection{The random strategy}
Here we consider $P = P^\mathit{eq}$ and $s$ the random strategy without repetition. 
We write $P$ instead of $P^s$.
\commentOC{We shouldn’t do that. We should rewrite this section to follow new notations and clarify (and continue)…}

When $\card{{\ppref_1}} = 1$, $P(\ppref_1) = \frac{1}{\card{Q}} \frac{1}{2}$.

Note that $P(\card{{\ppref_1}} = 1) = 1$, thus, $P(\ppref_2) = P(\ppref_2 \knowing \card{{\ppref_1}} = 1)$.

Let’s now evaluate $P(\ppref_2 \knowing \card{{\ppref_2}} = 2)$.
We may pick a question one end of which we know something about. There’s $2 (n - 2)$ such questions ($n - 2$ for each object in $\ppref_1$). If so, we need the answer to be oriented in a certain way to prevent transitive closure to bring anything new. Otherwise, we may pick a question whose two ends are yet unknown. There’s $n - 2$ choose $2$ such questions. Indeed, in total, there remains $2 (n - 2) + \frac{(n - 2) (n - 3)}{2} = \frac{(n - 2) (n + 1)}{2} = \frac{n (n - 1)}{2} - 1$ questions given $\ppref_1$.
Thus, $P(\ppref_2 \knowing \card{{\ppref_2}} = 2) = \frac{n - 1}{n + 1}$
(by noticing that $\card{Q_{\ppref_2}} = \frac{n(n-1)}{2}-1=\frac{(n-2)(n+1)}{2}$).

And $P(\ppref_2 \knowing \card{{\ppref_2}} = 3) = 2 \frac{2 (n - 2) 1/2}{(n - 2) (n + 1)} = \frac{2}{n + 1}$.

%\bibliography{bibl}

\appendix
\section{Best possible number of edges}
Assume we are the luckiest possible: we can choose the orientation of edges (the answers to questions) so as to maximise the number of resulting edges.

Define the \emph{original graph} as the graph $G$ containing the edge $(a, b)$ iff the question $a \relq b$ was asked and answered with $a > b$. Consider $k < n$. After $k$ questions, $G$ has $k$ edges at best.
The following proposition shows that to maximise the number of edges, it is necessary and sufficient to choose any $k + 1$ vertices and connect them. Note that any graph $G$ with $k$ edges can be uniquely decomposed into components having $k_1$, $k_2$, … edges, with $\sum_i k_i = k$ (in a component, there is a non-oriented path linking any two vertices of the component, and any two components are disconnected).
\begin{proposition}
	Let $G = (\allalts, E)$ be an oriented acyclic graph (not necessarily closed transitively) composed of components having $k_1$, $k_2$, … edges, with $\sum_i k_i = k$.
	Then, its transitive closure $T_G$ has $\binom{k + 1}{2}$ edges iff there is only one component having $k$ edges; otherwise, $T_G$ has less than $\binom{k + 1}{2}$ edges.
\end{proposition}
\begin{proof}[Folklore?]
	In general, $T_G$ has at most $\sum_i \binom{k_i + 1}{2}$ edges. The claim holds because $\binom{k + 1}{2} ≥ \sum_i \binom{k_i + 1}{2}$, with equality iff there is only one component.
	Indeed, the left hand side is half of $(k + 1) k = (\sum_i k_i + 1) \sum_i k_i = (\sum_i k_i)^2 + \sum_i k_i ≥ \sum_i k_i^2 + \sum_i k_i$, with equality iff there is only one component; whereas the right hand side is half of $\sum_i (k_i + 1) k_i = \sum_i k_i^2 + \sum_i k_i$.
\end{proof}

Idea: if I have two components, I must not attach to any of them a $k+2$nd element, otherwise, I have no hope of joining the components.

Idea2: Hyp, optimal strategies with $k-1$ questions or less are all connex. Prove that opt str with $k$ questions is connex. I know that $E^k > E^{k - 1} + 1$, where $E^k$ is the expected nm of edges with opt strat.

\section{Example context}
$N$ the voters (reviewers), $\card{N} = n$; $X$ the items (articles submitted to a conference), $\card{X} = m$. $PO(X)$ the partially ordered sets over $X$. Let $Q \in PO(X)^N$ represent some partial knowledge of the voters preferences. Consider $f: PO(X)^N → \powersetz{X}$ an enlarged voting rule, that selects winning items on the basis of partial knowledge of the preferences of the voters. Define $f(Q) = \min_{x \in X} \max_{y \in X, (>_{i \in N}) \in compl(Q)} s(y, (>_{i \in N})) - s(x, (>_{i \in N}))$ as selecting the alternatives that minimize the worst regret, where $s$ is the Borda scoring rule (attributing to an alternative at a profile as many points as that alternative beats other alternatives, summed over all voters).

We are interested in asking questions so as to let the regret diminish as fast as possible.
\end{document}

